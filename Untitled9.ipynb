{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chatbot Development"
      ],
      "metadata": {
        "id": "UlK5LxFP_bjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting Prompt"
      ],
      "metadata": {
        "id": "yhk3DmiI_kiI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9bEpOw0Y_WMM"
      },
      "outputs": [],
      "source": [
        "starting_prompt = \"Hello, I’m your financial assistant! How can I assist you today? You can ask me about stock predictions, commodity prices, or general market trends.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting LLM Parameters"
      ],
      "metadata": {
        "id": "2rlplrdZ_vHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature: It is set to 0.7 for balance between creativity and accuracy.\n",
        "\n",
        "Top P: 0.9 to maintain diverse but reasonable responses.\n",
        "\n",
        "Safety settings: It is to make sure to activate filters that prevent harmful or inappropriate content generation."
      ],
      "metadata": {
        "id": "RihxpvWo_0OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D84Zx90bXMBX",
        "outputId": "fdbee3a1-6881-4a89-85af-f9eff506c2f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your API key\n",
        "openai.api_key = ' sk-9A0y9pph7ogQH7jFmzXeUod3rEr4ZoM-a4eshIe2Y5T3BlbkFJdc6vbsZw_e9bAPuTd6KM04xEYlvZ-Ky5QkBWme1CIA'\n",
        "\n",
        "# Starting prompt for your chatbot\n",
        "starting_prompt = \"Hello, I’m your financial assistant! How can I assist you today? You can ask me about stock predictions, commodity prices, or general market trends.\"\n",
        "\n",
        "# Use ChatCompletion endpoint for chat models like GPT-4\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",  # Correct model type\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": starting_prompt}  # Defining the role and the initial message\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "# Print the chatbot's response\n",
        "print(response.choices[0].message[\"content\"])\n"
      ],
      "metadata": {
        "id": "X66igbX_AFn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1499b845-0495-4304-ddd7-be031d905ec6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, I can help you with that. Please note that I can provide general information about the stock market, but I cannot guarantee the accuracy of predictions as the stock market is influenced by a wide range of factors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Chatbot Prototype"
      ],
      "metadata": {
        "id": "JQ9JfKP1aS5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data (use historical data for assets like Tesla)\n",
        "data = pd.read_csv('tesla-stock-price.csv')\n"
      ],
      "metadata": {
        "id": "n38ljOwFcH0r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Check the data types of each column\n",
        "print(data.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i2QCWv3cFLa",
        "outputId": "17332655-8fc4-4b1a-8123-f6b5c1dfc576"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date   close         volume    open    high       low\n",
            "0       11:34  270.49      4,787,699  264.50  273.88  262.2400\n",
            "1  2018/10/15  259.59   6189026.0000  259.06  263.28  254.5367\n",
            "2  2018/10/12  258.78   7189257.0000  261.00  261.99  252.0100\n",
            "3  2018/10/11  252.23   8128184.0000  257.53  262.25  249.0300\n",
            "4  2018/10/10  256.88  12781560.0000  264.61  265.51  247.7700\n",
            "date       object\n",
            "close     float64\n",
            "volume     object\n",
            "open      float64\n",
            "high      float64\n",
            "low       float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any non-numeric columns, like date columns\n",
        "data_numeric = data.select_dtypes(include=[float, int])  # Keep only numeric data\n"
      ],
      "metadata": {
        "id": "kmi4xowKcLqV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert a date column to datetime, then to numeric timestamps\n",
        "# Replace 'Date' with the actual name of your date column\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "data['date'] = data['date'].apply(lambda x: x.timestamp())  # Convert to timestamp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JJjgbG7cReS",
        "outputId": "a5cfbfee-d11a-4b9a-9ba5-e659b2e2c452"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1684b7ec8ed0>:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data['date'] = pd.to_datetime(data['date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the numeric data\n",
        "scaled_data = (data_numeric - data_numeric.mean()) / data_numeric.std()\n"
      ],
      "metadata": {
        "id": "AgpO9jVIcnu1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'data' contains your raw data\n",
        "# Replace 'Close' with the actual target column name (stock price you're predicting)\n",
        "\n",
        "# Normalize the data (you can scale it as needed)\n",
        "data_numeric = data.select_dtypes(include=[float, int])\n",
        "\n",
        "# Replace 'Close' with the correct column name\n",
        "X = data_numeric.drop('close', axis=1)  # Features (all columns except target)\n",
        "y = data_numeric['close']  # Target (column you're predicting)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% for training, 20% for testing\n",
        "\n",
        "# Reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "x_train = x_train.values.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "x_test = x_test.values.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
        "\n",
        "# Prepare LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
        "\n",
        "# Predict next asset price\n",
        "predicted_price = model.predict(x_test)\n",
        "\n",
        "# Print the predicted prices\n",
        "print(predicted_price)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOToXmwMaLXQ",
        "outputId": "4d4da585-9536-4499-c348-fbd84d32197c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 38463.1211\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
            "[[277.44693]\n",
            " [277.45636]\n",
            " [277.46695]\n",
            " [277.4257 ]\n",
            " [277.442  ]\n",
            " [277.4646 ]\n",
            " [277.45804]\n",
            " [277.4602 ]\n",
            " [277.46487]\n",
            " [277.42365]\n",
            " [277.46185]\n",
            " [277.436  ]\n",
            " [277.4349 ]\n",
            " [277.43658]\n",
            " [277.46027]\n",
            " [277.46915]\n",
            " [277.4675 ]\n",
            " [277.43155]\n",
            " [277.46042]\n",
            " [277.42972]\n",
            " [277.46295]\n",
            " [277.4031 ]\n",
            " [277.44644]\n",
            " [277.46625]\n",
            " [277.4321 ]\n",
            " [277.44687]\n",
            " [277.45932]\n",
            " [277.4622 ]\n",
            " [277.42053]\n",
            " [277.4657 ]\n",
            " [277.41385]\n",
            " [277.44717]\n",
            " [277.46387]\n",
            " [277.4551 ]\n",
            " [277.46118]\n",
            " [277.42667]\n",
            " [277.46158]\n",
            " [277.43454]\n",
            " [277.43896]\n",
            " [277.4381 ]\n",
            " [277.428  ]\n",
            " [277.45703]\n",
            " [277.46198]\n",
            " [277.4659 ]\n",
            " [277.42966]\n",
            " [277.44766]\n",
            " [277.44055]\n",
            " [277.46213]\n",
            " [277.4294 ]\n",
            " [277.42816]\n",
            " [277.461  ]\n",
            " [277.433  ]\n",
            " [277.4662 ]\n",
            " [277.42654]\n",
            " [277.466  ]\n",
            " [277.4153 ]\n",
            " [277.46588]\n",
            " [277.42484]\n",
            " [277.38623]\n",
            " [277.46045]\n",
            " [277.46725]\n",
            " [277.46713]\n",
            " [277.45996]\n",
            " [277.43015]\n",
            " [277.44708]\n",
            " [277.44934]\n",
            " [277.4654 ]\n",
            " [277.46545]\n",
            " [277.4297 ]\n",
            " [277.46844]\n",
            " [277.46143]\n",
            " [277.43356]\n",
            " [277.43887]\n",
            " [277.46237]\n",
            " [277.43884]\n",
            " [277.46637]\n",
            " [277.43646]\n",
            " [277.46127]\n",
            " [277.46558]\n",
            " [277.4669 ]\n",
            " [277.4135 ]\n",
            " [277.45993]\n",
            " [277.46814]\n",
            " [277.46054]\n",
            " [277.46323]\n",
            " [277.46313]\n",
            " [277.441  ]\n",
            " [277.41965]\n",
            " [277.4663 ]\n",
            " [277.46353]\n",
            " [277.4654 ]\n",
            " [277.45447]\n",
            " [277.41626]\n",
            " [277.46405]\n",
            " [277.46768]\n",
            " [277.4511 ]\n",
            " [277.4509 ]\n",
            " [277.4572 ]\n",
            " [277.445  ]\n",
            " [277.42993]\n",
            " [277.4605 ]\n",
            " [277.4616 ]\n",
            " [277.4395 ]\n",
            " [277.46402]\n",
            " [277.46405]\n",
            " [277.45868]\n",
            " [277.46692]\n",
            " [277.41934]\n",
            " [277.44836]\n",
            " [277.42422]\n",
            " [277.43637]\n",
            " [277.45798]\n",
            " [277.44482]\n",
            " [277.44302]\n",
            " [277.43423]\n",
            " [277.46585]\n",
            " [277.43585]\n",
            " [277.4494 ]\n",
            " [277.43655]\n",
            " [277.44635]\n",
            " [277.46353]\n",
            " [277.4332 ]\n",
            " [277.44513]\n",
            " [277.46597]\n",
            " [277.4621 ]\n",
            " [277.46494]\n",
            " [277.46774]\n",
            " [277.46826]\n",
            " [277.46463]\n",
            " [277.4325 ]\n",
            " [277.42484]\n",
            " [277.42316]\n",
            " [277.46597]\n",
            " [277.45837]\n",
            " [277.4398 ]\n",
            " [277.4576 ]\n",
            " [277.4611 ]\n",
            " [277.46158]\n",
            " [277.42273]\n",
            " [277.4698 ]\n",
            " [277.438  ]\n",
            " [277.46896]\n",
            " [277.45905]\n",
            " [277.469  ]\n",
            " [277.44638]\n",
            " [277.44073]\n",
            " [277.46793]\n",
            " [277.46262]\n",
            " [277.4239 ]\n",
            " [277.46118]\n",
            " [277.46317]\n",
            " [277.4638 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "# Prepare LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model (assuming x_train and y_train are pre-processed)\n",
        "model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
        "\n",
        "# Predict next asset price\n",
        "predicted_price = model.predict(x_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VsuYNgMeKXs",
        "outputId": "39acf155-64ac-49f8-91d3-d0f96ff66a6a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 40754.7305\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG System (Document Retrieval)"
      ],
      "metadata": {
        "id": "-OboUAxPeh0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8gQKfWLez2-",
        "outputId": "abbe8b92-329b-4eab-ee2d-4f0b5d9855fd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Assuming we have a list of financial documents\n",
        "documents = [\"Market report 1\", \"Analysis report 2\"]\n",
        "\n",
        "# Create FAISS index for retrieval\n",
        "index = faiss.IndexFlatL2(512)  # 512-dimensional vectors\n",
        "vectors = np.random.random((len(documents), 512)).astype('float32')\n",
        "index.add(vectors)\n",
        "\n",
        "#Define the query vector (replace with your actual query vector)\n",
        "query_vector = np.random.random((1, 512)).astype('float32')  # Example random query vector\n",
        "\n",
        "# Query the index\n",
        "D, I = index.search(query_vector, k=1)  # k nearest neighbors\n",
        "retrieved_document = documents[I[0][0]]\n"
      ],
      "metadata": {
        "id": "fEe22fvOedmd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response Generation"
      ],
      "metadata": {
        "id": "a2XMQvZGfR1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(query):\n",
        "    prediction = predict_asset_price(query)\n",
        "    document = retrieve_document(query)\n",
        "\n",
        "    final_response = f\"{prediction}\\n\\nSupporting Document:\\n{document}\"\n",
        "    return final_response\n"
      ],
      "metadata": {
        "id": "ZNcqf7rQfJ_K"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "yf2D8M3Bgc3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query to test the chatbot\n",
        "user_query = \"What is the predicted price of Tesla stock next month?\"\n",
        "\n",
        "# Pass the user query to the chatbot and get a response\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": starting_prompt},  # Chatbot intro message\n",
        "        {\"role\": \"user\", \"content\": user_query}  # User input\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "# Print the chatbot's response\n",
        "print(\"Chatbot response:\", response.choices[0]['message']['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e65LmAfSfSgv",
        "outputId": "1863c91a-fc38-4e5c-acbf-9872b185d879"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot response: Sorry for the misunderstanding, but as an AI developed by OpenAI, I'm not capable of predicting specific future stock prices. These types of predictions require in-depth analysis and knowledge of the stock market, business fundamentals, and external factors affecting the company. It's recommended to consult with a financial advisor or conduct your own research when making investment decisions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Streamlit"
      ],
      "metadata": {
        "id": "oj1c2F8EgxAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlSoX8vPgsrk",
        "outputId": "7941b618-a0d8-4777-986b-d89d9788085c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.2)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.39.0 watchdog-5.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have an already trained LSTM model and scaling functions\n",
        "# Load your trained LSTM model (code for training LSTM comes from your previous steps)\n",
        "# Example:\n",
        "# model = load_model('lstm_model.h5')  # Load your pre-trained model here\n",
        "\n",
        "# Starting prompt for the chatbot\n",
        "starting_prompt = \"Hello, I’m your financial assistant! I can assist you with stock price predictions based on historical data analysis.\"\n",
        "\n",
        "# Function to generate response from OpenAI\n",
        "def get_chatbot_response(user_query):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": starting_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_query}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "    # Extract the response\n",
        "    chatbot_response = response.choices[0]['message']['content']\n",
        "\n",
        "    # Handle prediction requests using the LSTM model\n",
        "    if \"predict\" in user_query.lower():\n",
        "        # Example of handling stock prediction\n",
        "        # (You should preprocess the query and use your LSTM model here)\n",
        "        predicted_price = predict_stock_price()  # Call your LSTM model here\n",
        "        chatbot_response = f\"Based on historical data analysis, the predicted price is {predicted_price}.\"\n",
        "\n",
        "    return chatbot_response\n",
        "\n",
        "# Example function to use LSTM model to predict stock price\n",
        "def predict_stock_price():\n",
        "    # You would preprocess your data here, scale it, and pass it to the model\n",
        "    # Example: pred = model.predict(scaled_data)\n",
        "    return round(np.random.uniform(500, 1000), 2)  # Example placeholder prediction\n",
        "\n",
        "# Streamlit User Interface\n",
        "st.title(\"Finance Chatbot - Asset Price Prediction\")\n",
        "\n",
        "# Input text box for user query\n",
        "user_query = st.text_input(\"Enter your query:\")\n",
        "\n",
        "# Button to submit the query\n",
        "if st.button(\"Get Prediction\"):\n",
        "    if user_query:\n",
        "        # Get response from chatbot (integrated with LSTM prediction)\n",
        "        chatbot_response = get_chatbot_response(user_query)\n",
        "\n",
        "        # Display chatbot response\n",
        "        st.write(\"### Chatbot Response:\")\n",
        "        st.write(chatbot_response)\n",
        "    else:\n",
        "        st.write(\"Please enter a query!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgh8LIckgcCL",
        "outputId": "ce2d170d-2fbc-4b73-d3bb-16bad2df9643"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-10-24 07:52:56.514 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.648 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-10-24 07:52:56.649 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.654 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.659 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.660 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.662 Session state does not function when running a script without `streamlit run`\n",
            "2024-10-24 07:52:56.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.665 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.667 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.668 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.669 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.671 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:52:56.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example function for using LSTM model to predict stock price\n",
        "# You will replace this with your actual LSTM prediction function\n",
        "def predict_stock_price():\n",
        "    # Placeholder for actual prediction logic using LSTM model\n",
        "    # In your case, you would pass in the processed data to your LSTM model\n",
        "    # Example: pred = model.predict(processed_data)\n",
        "    return round(np.random.uniform(500, 1000), 2)  # Simulated prediction for now\n",
        "\n",
        "# Main function to handle user query and route to either GPT-4 or LSTM\n",
        "def handle_query(user_query):\n",
        "    # Check if the query is asking for a stock price prediction\n",
        "    if \"predict\" in user_query.lower() and \"price\" in user_query.lower():\n",
        "        # Call your LSTM model to predict stock price\n",
        "        predicted_price = predict_stock_price()\n",
        "        response = f\"Based on historical data analysis, the predicted stock price is ${predicted_price}.\"\n",
        "    else:\n",
        "        # For non-prediction queries, use GPT-4 to handle the response\n",
        "        response = get_gpt_response(user_query)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Streamlit User Interface\n",
        "st.title(\"Finance Chatbot - Asset Price Prediction\")\n",
        "\n",
        "# Input text box for user query\n",
        "user_query = st.text_input(\"Enter your query:\")\n",
        "\n",
        "# Button to submit the query\n",
        "if st.button(\"Get Prediction\"):\n",
        "    if user_query:\n",
        "        # Get response from chatbot (integrated with LSTM prediction)\n",
        "        chatbot_response = handle_query(user_query)\n",
        "\n",
        "        # Display chatbot response\n",
        "        st.write(\"### Chatbot Response:\")\n",
        "        st.write(chatbot_response)\n",
        "    else:\n",
        "        st.write(\"Please enter a query!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTKiFJdwg9wq",
        "outputId": "f6d52382-5432-403d-91a7-e0fa96257d7f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-10-24 07:55:09.613 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.617 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.622 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.624 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-24 07:55:09.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}