# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YDXoaO_7QO_SHFGMVPcNet0-yQDMictl

#Chatbot Development

Setting LLM Parameters

Temperature: It is set to 0.7 for balance between creativity and accuracy.

Top P: 0.9 to maintain diverse but reasonable responses.

Safety settings: It is to make sure to activate filters that prevent harmful or inappropriate content generation.
"""

!pip install openai

import openai

# Set your API key
openai.api_key = 'sk-wVGp8fGxdtPINgt6aLjOLWXRP490I2gFy9q--sJR8FT3BlbkFJj1hE5EqiHtlpLrj99tIJGoO7OFnJSP2yT5PzRpA6sA'

# Starting prompt for your chatbot
starting_prompt = "Hello, I’m your financial assistant! How can I assist you today? You can ask me about stock predictions, commodity prices, or general market trends."

# Use chat.completions.create for chat models like GPT-4
response = openai.chat.completions.create(
    model="gpt-4",  # Correct model type
    messages=[
        {"role": "system", "content": starting_prompt}  # Defining the role and the initial message
    ],
    temperature=0.7,
    top_p=0.9
)

# Print the chatbot's response
# Access the 'content' attribute of the message object using dot notation.
print(response.choices[0].message.content)

"""Building the Chatbot Prototype"""

import pandas as pd

# Load and preprocess data (use historical data for assets like Tesla)
data = pd.read_csv('tesla-stock-price.csv')

# Inspect the first few rows of the dataset
print(data.head())

# Check the data types of each column
print(data.dtypes)

# Drop any non-numeric columns, like date columns
data_numeric = data.select_dtypes(include=[float, int])  # Keep only numeric data

# Convert a date column to datetime, then to numeric timestamps
# Replace 'Date' with the actual name of your date column
data['date'] = pd.to_datetime(data['date'])
data['date'] = data['date'].apply(lambda x: x.timestamp())  # Convert to timestamp

# Normalize the numeric data
scaled_data = (data_numeric - data_numeric.mean()) / data_numeric.std()

import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.model_selection import train_test_split

# Assuming 'data' contains your raw data
# Replace 'Close' with the actual target column name (stock price you're predicting)

# Normalize the data (you can scale it as needed)
data_numeric = data.select_dtypes(include=[float, int])

# Replace 'Close' with the correct column name
X = data_numeric.drop('close', axis=1)  # Features (all columns except target)
y = data_numeric['close']  # Target (column you're predicting)

# Split data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% for training, 20% for testing

# Reshape input to be [samples, time steps, features] which is required for LSTM
x_train = x_train.values.reshape(x_train.shape[0], x_train.shape[1], 1)
x_test = x_test.values.reshape(x_test.shape[0], x_test.shape[1], 1)

# Prepare LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

# Compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train model
model.fit(x_train, y_train, batch_size=1, epochs=1)

# Predict next asset price
predicted_price = model.predict(x_test)

# Print the predicted prices
print(predicted_price)

import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import LSTM, Dense


# Prepare LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

# Compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train model (assuming x_train and y_train are pre-processed)
model.fit(x_train, y_train, batch_size=1, epochs=1)

# Predict next asset price
predicted_price = model.predict(x_test)

"""RAG System (Document Retrieval)"""

!pip install faiss-cpu

import faiss
import numpy as np

# Assuming we have a list of financial documents
documents = ["Market report 1", "Analysis report 2"]

# Create FAISS index for retrieval
index = faiss.IndexFlatL2(512)  # 512-dimensional vectors
vectors = np.random.random((len(documents), 512)).astype('float32')
index.add(vectors)

#Define the query vector (replace with your actual query vector)
query_vector = np.random.random((1, 512)).astype('float32')  # Example random query vector

# Query the index
D, I = index.search(query_vector, k=1)  # k nearest neighbors
retrieved_document = documents[I[0][0]]

"""Response Generation"""

def generate_response(query):
    prediction = predict_asset_price(query)
    document = retrieve_document(query)

    final_response = f"{prediction}\n\nSupporting Document:\n{document}"
    return final_response

"""Testing"""

# ipython-input-22-f1af262a5169.py
!pip install --upgrade openai
import os
import openai

# Set the OpenAI API key as an environment variable correctly
os.environ["OPENAI_API_KEY"] = "sk-wVGp8fGxdtPINgt6aLjOLWXRP490I2gFy9q--sJR8FT3BlbkFJj1hE5EqiHtlpLrj99tIJGoO7OFnJSP2yT5PzRpA6sA"  # Replace with your actual key

# Example query to test the chatbot
user_query = "What is the predicted price of Tesla stock next month?"

# Pass the user query to the chatbot and get a response
client = openai.OpenAI()  # Create an OpenAI client instance
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": starting_prompt},  # Chatbot intro message
        {"role": "user", "content": user_query}  # User input
    ],
    temperature=0.7,
    top_p=0.9
)

# Print the chatbot's response
print("Chatbot response:", response.choices[0].message.content)

"""Install Streamlit"""

pip install streamlit

import openai
import streamlit as st
import numpy as np

# Assuming you have an already trained LSTM model and scaling functions
# Load your trained LSTM model (code for training LSTM comes from your previous steps)
# Example:
# model = load_model('lstm_model.h5')  # Load your pre-trained model here

# Starting prompt for the chatbot
starting_prompt = "Hello, I’m your financial assistant! I can assist you with stock price predictions based on historical data analysis."

# Function to generate response from OpenAI
def get_chatbot_response(user_query):
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": starting_prompt},
            {"role": "user", "content": user_query}
        ],
        temperature=0.7,
        top_p=0.9
    )

    # Extract the response
    chatbot_response = response.choices[0]['message']['content']

    # Handle prediction requests using the LSTM model
    if "predict" in user_query.lower():
        # Example of handling stock prediction
        # (You should preprocess the query and use your LSTM model here)
        predicted_price = predict_stock_price()  # Call your LSTM model here
        chatbot_response = f"Based on historical data analysis, the predicted price is {predicted_price}."

    return chatbot_response

# Example function to use LSTM model to predict stock price
def predict_stock_price():
    # You would preprocess your data here, scale it, and pass it to the model
    # Example: pred = model.predict(scaled_data)
    return round(np.random.uniform(500, 1000), 2)  # Example placeholder prediction

# Streamlit User Interface
st.title("Finance Chatbot - Asset Price Prediction")

# Input text box for user query
user_query = st.text_input("Enter your query:")

# Button to submit the query
if st.button("Get Prediction"):
    if user_query:
        # Get response from chatbot (integrated with LSTM prediction)
        chatbot_response = get_chatbot_response(user_query)

        # Display chatbot response
        st.write("### Chatbot Response:")
        st.write(chatbot_response)
    else:
        st.write("Please enter a query!")

# Example function for using LSTM model to predict stock price
# You will replace this with your actual LSTM prediction function
def predict_stock_price():
    # Placeholder for actual prediction logic using LSTM model
    # In your case, you would pass in the processed data to your LSTM model
    # Example: pred = model.predict(processed_data)
    return round(np.random.uniform(500, 1000), 2)  # Simulated prediction for now

# Main function to handle user query and route to either GPT-4 or LSTM
def handle_query(user_query):
    # Check if the query is asking for a stock price prediction
    if "predict" in user_query.lower() and "price" in user_query.lower():
        # Call your LSTM model to predict stock price
        predicted_price = predict_stock_price()
        response = f"Based on historical data analysis, the predicted stock price is ${predicted_price}."
    else:
        # For non-prediction queries, use GPT-4 to handle the response
        response = get_gpt_response(user_query)

    return response

# Streamlit User Interface
st.title("Finance Chatbot - Asset Price Prediction")

# Input text box for user query
user_query = st.text_input("Enter your query:")

# Button to submit the query
if st.button("Get Prediction"):
    if user_query:
        # Get response from chatbot (integrated with LSTM prediction)
        chatbot_response = handle_query(user_query)

        # Display chatbot response
        st.write("### Chatbot Response:")
        st.write(chatbot_response)
    else:
        st.write("Please enter a query!")